{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwiks9635/Segmentation-Model/blob/main/Image_Segmentation_Using_UNet_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGt-WQITuoUn"
      },
      "source": [
        "#**Image Segmentation Using Tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DIsnHc3unld"
      },
      "outputs": [],
      "source": [
        "!unzip /content/https:/www.kaggle.com/datasets/dansbecker/cityscapes-image-pairs/cityscapes-image-pairs.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcH7b42Kvixl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N90UsvXdweDC"
      },
      "outputs": [],
      "source": [
        "plt.style.use(\"seaborn-darkgrid\")\n",
        "\n",
        "sns.set_context(\"paper\", font_scale=1.4)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "id_map = {\n",
        "    0: (0, 0, 0), # unlabelled\n",
        "    1: (111, 74,  0), #static\n",
        "    2: ( 81,  0, 81), #ground\n",
        "    3: (128, 64,127), #road\n",
        "    4: (244, 35,232), #sidewalk\n",
        "    5: (250,170,160), #parking\n",
        "    6: (230,150,140), #rail track\n",
        "    7: (70, 70, 70), #building\n",
        "    8: (102,102,156), #wall\n",
        "    9: (190,153,153), #fence\n",
        "    10: (180,165,180), #guard rail\n",
        "    11: (150,100,100), #bridge\n",
        "    12: (150,120, 90), #tunnel\n",
        "    13: (153,153,153), #pole\n",
        "    14: (153,153,153), #polegroup\n",
        "    15: (250,170, 30), #traffic light\n",
        "    16: (220,220,  0), #traffic sign\n",
        "    17: (107,142, 35), #vegetation\n",
        "    18: (152,251,152), #terrain\n",
        "    19: ( 70,130,180), #sky\n",
        "    20: (220, 20, 60), #person\n",
        "    21: (255,  0,  0), #rider\n",
        "    22: (  0,  0,142), #car\n",
        "    23: (  0,  0, 70), #truck\n",
        "    24: (  0, 60,100), #bus\n",
        "    25: (  0,  0, 90), #caravan\n",
        "    26: (  0,  0,110), #trailer\n",
        "    27: (  0, 80,100), #train\n",
        "    28: (  0,  0,230), #motorcycle\n",
        "    29: (119, 11, 32), #bicycle\n",
        "    30: (  0,  0,142) #license plate\n",
        "}\n",
        "\n",
        "category_map = {\n",
        "    0: 0,\n",
        "    1: 0,\n",
        "    2: 0,\n",
        "    3: 1,\n",
        "    4: 1,\n",
        "    5: 1,\n",
        "    6: 1,\n",
        "    7: 2,\n",
        "    8: 2,\n",
        "    9: 2,\n",
        "    10: 2,\n",
        "    11: 2,\n",
        "    12: 2,\n",
        "    13: 3,\n",
        "    14: 3,\n",
        "    15: 3,\n",
        "    16: 3,\n",
        "    17: 4,\n",
        "    18: 4,\n",
        "    19: 5,\n",
        "    20: 6,\n",
        "    21: 6,\n",
        "    22: 7,\n",
        "    23: 7,\n",
        "    24: 7,\n",
        "    25: 7,\n",
        "    26: 7,\n",
        "    27: 7,\n",
        "    28: 7,\n",
        "    29: 7,\n",
        "    30: 7\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4fiz6kcwkjX"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/cityscapes_data/train\"\n",
        "valid_path = \"/content/cityscapes_data/val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR-SVJgK0IkC"
      },
      "outputs": [],
      "source": [
        "len(os.listdir(train_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6kzg14wxvdt"
      },
      "outputs": [],
      "source": [
        "num_classes = len(id_map.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6pOBYEhx28z"
      },
      "outputs": [],
      "source": [
        "def preprocess(path):\n",
        "    img = Image.open(path)\n",
        "    img1 = img.crop((0, 0, 256, 256)).resize((128, 128))\n",
        "    img2 = img.crop((256, 0, 512, 256)).resize((128, 128))\n",
        "    img1 = np.array(img1) / 255.\n",
        "    img2 = np.array(img2)\n",
        "    mask = np.zeros(shape=(img2.shape[0], img2.shape[1]), dtype = np.uint32)\n",
        "    for row in range(img2.shape[0]):\n",
        "        for col in range(img2.shape[1]):\n",
        "            a = img2[row, col, :]\n",
        "            final_key = None\n",
        "            final_d = None\n",
        "            for key, value in id_map.items():\n",
        "                d = np.sum(np.sqrt(pow(a - value, 2)))\n",
        "                if final_key == None:\n",
        "                    final_d = d\n",
        "                    final_key = key\n",
        "                elif d < final_d:\n",
        "                    final_d = d\n",
        "                    final_key = key\n",
        "            mask[row, col] = final_key\n",
        "    mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "    del img2\n",
        "    return img1, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaCbHvKaybld"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(train_path, valid_path):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    x_valid = []\n",
        "    y_valid = []\n",
        "\n",
        "    for path in tqdm(os.listdir(train_path)):\n",
        "        img, mask = preprocess(os.path.join(train_path, path))\n",
        "        x_train.append(img)\n",
        "        y_train.append(mask)\n",
        "\n",
        "\n",
        "    for path in tqdm(os.listdir(valid_path)):\n",
        "        img, mask = preprocess(os.path.join(valid_path, path))\n",
        "        x_valid.append(img)\n",
        "        y_valid.append(mask)\n",
        "\n",
        "    return x_train, y_train, x_valid, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu0gpnSP1Q9g"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_valid, y_valid = prepare_dataset(train_path, valid_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet_model():\n",
        "\n",
        "    inputs = layers.Input(shape = [128, 128, 3])\n",
        "\n",
        "    #First Downsample\n",
        "    f1 = layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(inputs)\n",
        "    b1 = layers.BatchNormalization()(f1)\n",
        "    f2 = layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b1)    # Used later for residual connection\n",
        "\n",
        "    m3 = layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f2)\n",
        "    d4 = layers.Dropout(0.2)(m3)\n",
        "\n",
        "    # Second Downsample\n",
        "    f5 = layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d4)\n",
        "    b5 = layers.BatchNormalization()(f5)\n",
        "    f6 = layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b5)    # Used later for residual connection\n",
        "\n",
        "    m7 = layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f6)\n",
        "    d8 = layers.Dropout(0.2)(m7)\n",
        "\n",
        "    # Third Downsample\n",
        "    f9 = layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d8)\n",
        "    b9 = layers.BatchNormalization()(f9)\n",
        "    f10 = layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b9)    # Used later for residual connection\n",
        "\n",
        "    m11 = layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f10)\n",
        "    d12 = layers.Dropout(0.2)(m11)\n",
        "\n",
        "    #Forth Downsample\n",
        "    f13 = layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d12)\n",
        "    b13 = layers.BatchNormalization()(f13)\n",
        "    f14 = layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b13)    # Used later for residual connection\n",
        "\n",
        "    m15 = layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f14)\n",
        "    d16 = layers.Dropout(0.2)(m15)\n",
        "\n",
        "    #Fifth Downsample\n",
        "    f17 = layers.Conv2D(1024, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d16)\n",
        "    b17 = layers.BatchNormalization()(f17)\n",
        "    f18 = layers.Conv2D(1024, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b17)\n",
        "\n",
        "\n",
        "    # First Upsample\n",
        "    m19 = layers.UpSampling2D(size = (2, 2))(f18)\n",
        "    d19 = layers.Dropout(0.2)(m19)\n",
        "    c20 = layers.Concatenate()([d19, f14])\n",
        "    f21 = layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1 ,activation = \"relu\")(c20)\n",
        "    b21 = layers.BatchNormalization()(f21)\n",
        "    f22 = layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b21)\n",
        "\n",
        "    # Second Upsample\n",
        "    m23 = layers.UpSampling2D(size = (2, 2))(f22)\n",
        "    d23 = layers.Dropout(0.2)(m23)\n",
        "    c24 = layers.Concatenate()([d23, f10])\n",
        "    f25 = layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c24)\n",
        "    b25 = layers.BatchNormalization()(f25)\n",
        "    f26 = layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b25)\n",
        "\n",
        "    # Third Upsample\n",
        "    m27 = layers.UpSampling2D(size = (2, 2))(f26)\n",
        "    d27 = layers.Dropout(0.2)(m27)\n",
        "    c28 = layers.Concatenate()([d27, f6])\n",
        "    f29 = layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c28)\n",
        "    b29 = layers.BatchNormalization()(f29)\n",
        "    f30 = layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b29)\n",
        "\n",
        "    #Forth Upsample\n",
        "    m31 = layers.UpSampling2D(size = (2, 2))(f30)\n",
        "    d31 = layers.Dropout(0.2)(m31)\n",
        "    c32 = layers.Concatenate()([d31, f2])\n",
        "    f33 = layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c32)\n",
        "    b33 = layers.BatchNormalization()(f33)\n",
        "    f34 = layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b33)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Conv2D(num_classes, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"softmax\")(f34)\n",
        "\n",
        "    model = keras.Model(inputs = [inputs], outputs = [outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "nlKJWkvM6RM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_unet_model()\n",
        "keras.utils.plot_model(model, show_shapes = True)"
      ],
      "metadata": {
        "id": "K3UTcOZ69J-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpdatedMeanIoU(keras.metrics.MeanIoU):\n",
        "  def __init__(self,\n",
        "               y_true=None,\n",
        "               y_pred=None,\n",
        "               num_classes=None,\n",
        "               name=None,\n",
        "               dtype=None):\n",
        "    super(UpdatedMeanIoU, self).__init__(num_classes = num_classes,name=name, dtype=dtype)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    return super().update_state(y_true, y_pred, sample_weight)"
      ],
      "metadata": {
        "id": "oTecK6qz_ebz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VizCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, file_path, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        img, mask = preprocess(self.file_path)\n",
        "        img = np.array(img)\n",
        "        img = np.reshape(img, (1, 128, 128, 3))\n",
        "        pred = model.predict(img)\n",
        "        y_pred = tf.math.argmax(pred, axis=-1)\n",
        "        y_pred = np.array(y_pred)\n",
        "        y_pred = np.reshape(y_pred, (128, 128))\n",
        "        fig, axes = plt.subplots(nrows = 1, ncols = 2)\n",
        "        axes[0].imshow(mask)\n",
        "        axes[0].set_title(\"Original Mask\")\n",
        "        axes[1].imshow(y_pred)\n",
        "        axes[1].set_title(\"Predicted Mask\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "1fcLyHk1BY-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(20, 7))\n",
        "  # Training\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"loss\"], ax = axes[0], label=\"Training Loss\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"accuracy\"], ax = axes[1], label=\"Training Accuracy\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"mean_iou\"], ax = axes[2], label=\"Training Mean IOU\")\n",
        "\n",
        "  # Validation\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_loss\"], ax = axes[0], label=\"Validation Loss\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_accuracy\"], ax = axes[1], label=\"Validation Accuracy\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_mean_iou\"], ax = axes[2], label=\"Validation Mean IOU\")\n",
        "\n",
        "  axes[0].set_title(\"Loss Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[0].set_xlabel(\"Epoch\")\n",
        "  axes[0].set_ylabel(\"Loss\")\n",
        "\n",
        "  axes[1].set_title(\"Accuracy Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[1].set_xlabel(\"Epoch\")\n",
        "  axes[1].set_ylabel(\"Accuracy\")\n",
        "\n",
        "  axes[2].set_title(\"Mean IOU Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[2].set_xlabel(\"Epoch\")\n",
        "  axes[2].set_ylabel(\"Mean IOU\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ZRE5ZqR-BgyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    metrics = [\"accuracy\", UpdatedMeanIoU(num_classes=num_classes, name = \"mean_iou\")])"
      ],
      "metadata": {
        "id": "ed1ibkrrB1xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience = 10, restore_best_weights = True)\n",
        "viz_callback = VizCallback(\"/content/cityscapes_data/val/108.jpg\")"
      ],
      "metadata": {
        "id": "DVi46fDLChNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_valid = np.array(x_valid)\n",
        "y_valid = np.array(y_valid)"
      ],
      "metadata": {
        "id": "iFbI_EJrC5Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x = x_train, y = y_train, epochs = 100, batch_size = batch_size, validation_data = (x_valid, y_valid), callbacks=[early_stopping, viz_callback])"
      ],
      "metadata": {
        "id": "cDEtKDtECzMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "VPM0qkisDUL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"default\")\n",
        "for i in os.listdir(valid_path)[:3]:\n",
        "    img, mask = preprocess(os.path.join(valid_path, i))\n",
        "    img = np.array(img)\n",
        "    img = np.reshape(img, (1, 128, 128, 3))\n",
        "    pred = model.predict(img)\n",
        "    y_pred = tf.math.argmax(pred, axis=-1)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_pred = np.reshape(y_pred, (128, 128))\n",
        "    fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(10, 5))\n",
        "    img = np.reshape(img, (128, 128, 3))\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[1].imshow(mask, cmap=\"viridis\")\n",
        "    axes[1].set_title(\"Original Mask\")\n",
        "    axes[1].axis(\"off\")\n",
        "    axes[2].imshow(y_pred, cmap=\"viridis\")\n",
        "    axes[2].set_title(\"Predicted Mask\")\n",
        "    axes[2].axis(\"off\")"
      ],
      "metadata": {
        "id": "K_WFuCVpD9xH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}